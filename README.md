# Premium AI-Based Real-Time Sign Language Translator

![AI](https://img.shields.io/badge/AI-Mediapipe%20%2B%20TensorFlow-blue)
![Frontend](https://img.shields.io/badge/Frontend-React%20%2B%20Tailwind-indigo)
![Backend](https://img.shields.io/badge/Backend-Flask-green)

A production-ready system for real-time sign language translation using Computer Vision and Deep Learning. Features a premium dashboard inspired by Apple and Tesla design aesthetics.

## ğŸš€ Key Features
- **Real-time Detection**: 30 FPS hand landmark tracking using MediaPipe.
- **Gesture Classification**: Multi-class CNN model for static signs.
- **Sentence Builder**: Intelligent debouncing and sentence formation logic.
- **Voice Synthesis**: Natural Text-to-Speech (TTS) integration.
- **Premium UI**: Glassmorphism, dark mode, and Framer Motion animations.
- **Training Suite**: Built-in data collection and training scripts for custom gestures.

## ğŸ› ï¸ Tech Stack
- **AI**: Python, MediaPipe, TensorFlow/Keras, OpenCV, NumPy.
- **Backend**: Flask, TextBlob (Grammar), pyttsx3 (Voice).
- **Frontend**: React.js, TailwindCSS, Framer Motion, Lucide Icons.

## ğŸ“‚ Project Structure
```text
backend/
â”œâ”€â”€ app.py              # Main Flask API
â”œâ”€â”€ model/              # Trained .h5 models
â”œâ”€â”€ training/           # Data collection & training scripts
â”‚   â”œâ”€â”€ collect_data.py # Capture landmarks from webcam
â”‚   â””â”€â”€ train_model.py  # Train CNN/Dense model
â”œâ”€â”€ utils.py            # AI Helper classes (HandDetector, Predictor)
â””â”€â”€ requirements.txt    # Python dependencies

frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.jsx         # Premium Dashboard Container
â”‚   â””â”€â”€ index.css       # Global Premium Design System
â””â”€â”€ ...
```

## âš™ï¸ Setup Instructions

### 1. Backend Setup
1. Open a terminal in the `backend` folder.
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. (Optional) Run the dummy model generator if you want to test without training:
   ```bash
   python ../generate_dummy_models.py
   ```
4. Start the Flask server:
   ```bash
   python app.py
   ```

### 2. Frontend Setup
1. Open a terminal in the `frontend` folder.
2. Install dependencies:
   ```bash
   npm install
   ```
3. Start the Vite dev server:
   ```bash
   npm run dev
   ```

### 3. Training Custom Gestures
1. Run `python backend/training/collect_data.py`.
2. Follow the on-screen prompts to record 30 sequences for each sign.
3. Run `python backend/training/train_model.py` to generate your new `hand_model.h5`.

## ğŸ“„ Resume Description
**Senior AI Engineer / Full Stack Developer**
*Developed a real-time Sign Language Translation system using Mediapipe and TensorFlow, achieving 95%+ accuracy for static gestures. Built a high-performance Flask API to handle computer vision processing and integrated a React-based premium dashboard with 60FPS webcam streaming and real-time TTS output. Implemented a custom data collection pipeline and CNN-based classification engine for accessible communication tools.*

## ğŸŒ Deployment
- **Backend**: Deploy to **Render** or **AWS EC2** (requires high CPU/RAM for MediaPipe).
- **Frontend**: Deploy to **Vercel** or **Netlify**.
- **Model Storage**: Use **Firebase Storage** or S3 for large `.h5` files.

---


# sign_sync_ai
